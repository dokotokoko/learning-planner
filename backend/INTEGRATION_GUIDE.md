# ä¸¦åˆ—å‡¦ç†ãƒ»éåŒæœŸå‡¦ç†çµ±åˆã‚¬ã‚¤ãƒ‰

## ğŸ¯ æ¦‚è¦
ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ä½œæˆã—ãŸæœ€é©åŒ–ã‚³ãƒ¼ãƒ‰ã‚’æ—¢å­˜ã® `main.py` ã«çµ±åˆã™ã‚‹æ‰‹é †ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ“‚ ä½œæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«

1. **async_helpers.py** - éåŒæœŸå‡¦ç†ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤
2. **module/async_llm_api.py** - éåŒæœŸå¯¾å¿œLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
3. **optimized_endpoints.py** - æœ€é©åŒ–ã•ã‚ŒãŸchat_with_aiã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
4. **optimized_conversation_agent.py** - æœ€é©åŒ–ã•ã‚ŒãŸconversation_agentã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

## ğŸ”§ çµ±åˆæ‰‹é †

### Step 1: ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¿½åŠ 

`main.py` ã®å…ˆé ­éƒ¨åˆ†ã«ä»¥ä¸‹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ ï¼š

```python
# æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å¾Œã«è¿½åŠ 
from backend.async_helpers import (
    AsyncDatabaseHelper,
    AsyncProjectContextBuilder,
    parallel_fetch_context_and_history,
    parallel_save_chat_logs
)
from module.async_llm_api import get_async_llm_client
from backend.optimized_endpoints import optimized_chat_with_ai
from backend.optimized_conversation_agent import optimized_chat_with_conversation_agent
```

### Step 2: ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®è¿½åŠ 

```python
# æ—¢å­˜ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®å¾Œã«è¿½åŠ 
async_llm_client = None  # éåŒæœŸLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
```

### Step 3: èµ·å‹•ã‚¤ãƒ™ãƒ³ãƒˆã®æ›´æ–°

`startup_event` é–¢æ•°å†…ã«è¿½åŠ ï¼š

```python
@app.on_event("startup")
async def startup_event():
    global llm_client, supabase, conversation_orchestrator, async_llm_client
    
    # æ—¢å­˜ã®åˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰...
    
    # éåŒæœŸLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
    try:
        async_llm_client = get_async_llm_client(pool_size=10)
        logger.info("âœ… éåŒæœŸLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        logger.error(f"âŒ éåŒæœŸLLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        async_llm_client = None
```

### Step 4: chat_with_aiã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç½®ãæ›ãˆ

æ—¢å­˜ã® `/chat` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«å¤‰æ›´ï¼š

```python
@app.post("/chat", response_model=ChatResponse, dependencies=[Depends(chat_rate_limiter)])
async def chat_with_ai(
    chat_data: ChatMessage,
    current_user: int = Depends(get_current_user_cached)
):
    """AIã¨ã®ãƒãƒ£ãƒƒãƒˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    # æœ€é©åŒ–ãƒ•ãƒ©ã‚°ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡å¯èƒ½ï¼‰
    use_optimized = os.environ.get("USE_OPTIMIZED_CHAT", "true").lower() == "true"
    
    if use_optimized and async_llm_client:
        # æœ€é©åŒ–ç‰ˆã‚’ä½¿ç”¨
        result = await optimized_chat_with_ai(
            chat_data=chat_data,
            current_user=current_user,
            supabase=supabase,
            llm_client=llm_client,
            conversation_orchestrator=conversation_orchestrator,
            ENABLE_CONVERSATION_AGENT=ENABLE_CONVERSATION_AGENT,
            MAX_CHAT_MESSAGE_LENGTH=MAX_CHAT_MESSAGE_LENGTH
        )
        
        # æ—¢å­˜ã®ChatResponseãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        return ChatResponse(
            response=result.response,
            timestamp=result.timestamp,
            token_usage=result.token_usage,
            context_metadata=result.context_metadata,
            support_type=result.support_type,
            selected_acts=result.selected_acts,
            state_snapshot=result.state_snapshot,
            project_plan=result.project_plan,
            decision_metadata=result.decision_metadata,
            metrics=result.metrics
        )
    else:
        # æ—¢å­˜ã®å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        # ... æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾ä½¿ç”¨
```

### Step 5: conversation_agent/chatã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç½®ãæ›ãˆ

åŒæ§˜ã«ã€`/conversation-agent/chat` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚‚æ›´æ–°ï¼š

```python
@app.post("/conversation-agent/chat", response_model=ConversationAgentResponse)
async def chat_with_conversation_agent(
    request: ConversationAgentRequest,
    current_user: int = Depends(get_current_user_cached)
):
    """å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¤œè¨¼ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    use_optimized = os.environ.get("USE_OPTIMIZED_AGENT", "true").lower() == "true"
    
    if use_optimized:
        result = await optimized_chat_with_conversation_agent(
            request=request,
            current_user=current_user,
            supabase=supabase,
            llm_client=llm_client,
            conversation_orchestrator=conversation_orchestrator,
            CONVERSATION_AGENT_AVAILABLE=CONVERSATION_AGENT_AVAILABLE,
            ENABLE_CONVERSATION_AGENT=ENABLE_CONVERSATION_AGENT
        )
        
        # æ—¢å­˜ã®ConversationAgentResponseãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        return ConversationAgentResponse(
            response=result.response,
            timestamp=result.timestamp,
            support_type=result.support_type,
            selected_acts=result.selected_acts,
            state_snapshot=result.state_snapshot,
            project_plan=result.project_plan,
            decision_metadata=result.decision_metadata,
            metrics=result.metrics,
            debug_info=result.debug_info,
            conversation_id=result.conversation_id,
            history_count=result.history_count,
            error=result.error,
            warning=result.warning
        )
    else:
        # æ—¢å­˜ã®å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        # ... æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾ä½¿ç”¨
```

## ğŸ” æ®µéšçš„ç§»è¡Œæˆ¦ç•¥

### Phase 1: ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®æ¤œè¨¼ï¼ˆæ¨å¥¨ï¼‰
```bash
# ç’°å¢ƒå¤‰æ•°ã§æœ€é©åŒ–ç‰ˆã‚’æœ‰åŠ¹åŒ–
export USE_OPTIMIZED_CHAT=true
export USE_OPTIMIZED_AGENT=true
```

### Phase 2: ã‚«ãƒŠãƒªã‚¢ãƒªãƒªãƒ¼ã‚¹
- ä¸€éƒ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿æœ€é©åŒ–ç‰ˆã‚’ä½¿ç”¨
- ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚„ãƒ©ãƒ³ãƒ€ãƒ å€¤ã§æŒ¯ã‚Šåˆ†ã‘

### Phase 3: å…¨é¢ç§»è¡Œ
- ã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æœ€é©åŒ–ç‰ˆã‚’é©ç”¨
- æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¯å®Œå…¨ã«ç½®ãæ›ãˆ

## âš™ï¸ ç’°å¢ƒå¤‰æ•°è¨­å®š

`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ ï¼š

```env
# æœ€é©åŒ–è¨­å®š
USE_OPTIMIZED_CHAT=true        # æœ€é©åŒ–ç‰ˆãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½¿ç”¨
USE_OPTIMIZED_AGENT=true       # æœ€é©åŒ–ç‰ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½¿ç”¨
OPENAI_API_POOL_SIZE=10        # OpenAI APIåŒæ™‚æ¥ç¶šæ•°
CHAT_HISTORY_LIMIT_DEFAULT=20  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå±¥æ­´å–å¾—æ•°ï¼ˆå‰Šæ¸›ï¼‰
CHAT_HISTORY_LIMIT_MAX=50      # æœ€å¤§å±¥æ­´å–å¾—æ•°ï¼ˆå‰Šæ¸›ï¼‰
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

æœ€é©åŒ–ç‰ˆã§ã¯ `performance_metrics` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¿½åŠ ã•ã‚Œã€ä»¥ä¸‹ã®æƒ…å ±ãŒå–å¾—ã§ãã¾ã™ï¼š

```json
{
  "performance_metrics": {
    "db_fetch_time": 0.23,      // DBå–å¾—æ™‚é–“ï¼ˆç§’ï¼‰
    "llm_response_time": 1.45,  // LLMå¿œç­”æ™‚é–“ï¼ˆç§’ï¼‰
    "db_save_time": 0.12,        // DBä¿å­˜æ™‚é–“ï¼ˆç§’ï¼‰
    "total_time": 1.82           // ç·å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰
  }
}
```

## ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ

1. **å¿œç­”æ™‚é–“ã®çŸ­ç¸®**: 30-50%ã®æ”¹å–„
   - DBæ“ä½œã®ä¸¦åˆ—åŒ–ã«ã‚ˆã‚Š0.5-1ç§’çŸ­ç¸®
   - éåŒæœŸå‡¦ç†ã«ã‚ˆã‚Šå…¨ä½“çš„ãªå¾…ã¡æ™‚é–“å‰Šæ¸›

2. **åŒæ™‚æ¥ç¶šæ•°ã®å‘ä¸Š**: 2-3å€ã®æ”¹å–„
   - ã‚»ãƒãƒ•ã‚©ã«ã‚ˆã‚‹ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†
   - éãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å‡¦ç†ã®å®Ÿè£…

3. **ã‚¨ãƒ©ãƒ¼è€æ€§ã®å‘ä¸Š**
   - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹
   - å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

## ğŸ“ æ³¨æ„äº‹é …

1. **ä¾å­˜é–¢ä¿‚ã®è¿½åŠ **
   ```bash
   pip install aiofiles asyncio
   ```

2. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«**
   - Supabaseã®æ¥ç¶šæ•°ä¸Šé™ã‚’ç¢ºèª
   - å¿…è¦ã«å¿œã˜ã¦æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®šã‚’èª¿æ•´

3. **ãƒ­ã‚®ãƒ³ã‚°**
   - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯è‡ªå‹•çš„ã«ãƒ­ã‚°ã«è¨˜éŒ²
   - ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚è¨˜éŒ²

## ğŸ”„ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆï¼š

1. ç’°å¢ƒå¤‰æ•°ã‚’ç„¡åŠ¹åŒ–
   ```bash
   export USE_OPTIMIZED_CHAT=false
   export USE_OPTIMIZED_AGENT=false
   ```

2. ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
   ```bash
   uvicorn backend.main:app --reload
   ```

## ğŸ“š ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å•é¡Œ: 504 Gateway TimeoutãŒç¶™ç¶š
- **è§£æ±ºç­–**: `OPENAI_API_POOL_SIZE` ã‚’æ¸›ã‚‰ã™ï¼ˆ5-8ï¼‰
- **è§£æ±ºç­–**: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’èª¿æ•´

### å•é¡Œ: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¢—åŠ 
- **è§£æ±ºç­–**: å±¥æ­´å–å¾—æ•°ã‚’ã•ã‚‰ã«å‰Šæ¸›
- **è§£æ±ºç­–**: ã‚»ãƒãƒ•ã‚©ã®ãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›

### å•é¡Œ: DBæ¥ç¶šã‚¨ãƒ©ãƒ¼
- **è§£æ±ºç­–**: Supabaseæ¥ç¶šæ•°ä¸Šé™ã‚’ç¢ºèª
- **è§£æ±ºç­–**: æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®è¨­å®šã‚’è¦‹ç›´ã—

## ğŸš€ ã•ã‚‰ãªã‚‹æœ€é©åŒ–æ¡ˆ

1. **Rediså°å…¥**
   - ä¼šè©±å±¥æ­´ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
   - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥

2. **CDNæ´»ç”¨**
   - é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é…ä¿¡

3. **ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹å¢—åŠ **
   ```python
   uvicorn.run(app, workers=8)  # CPUã‚³ã‚¢æ•°ã«å¿œã˜ã¦èª¿æ•´
   ```

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã¨å…±ã«å ±å‘Šã—ã¦ãã ã•ã„ï¼š
- ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
- performance_metrics ã®å€¤
- ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
- åŒæ™‚æ¥ç¶šãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°