"""
æœ€é©åŒ–ã•ã‚ŒãŸAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
ä¸¦åˆ—å‡¦ç†ã¨éåŒæœŸå‡¦ç†ã‚’æ´»ç”¨ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„
"""

import asyncio
import json
import time
import logging
from typing import Optional, Dict, Any, List
from datetime import datetime, timezone
from fastapi import HTTPException, Depends, status
from pydantic import BaseModel

from async_helpers import (
    AsyncDatabaseHelper,
    AsyncProjectContextBuilder,
    parallel_fetch_context_and_history,
    parallel_save_chat_logs,
    rate_limited_openai_call
)
from module.async_llm_api import get_async_llm_client

logger = logging.getLogger(__name__)


class OptimizedChatResponse(BaseModel):
    """æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    response: str
    timestamp: str
    token_usage: Optional[Dict[str, Any]] = None
    context_metadata: Optional[Dict[str, Any]] = None
    support_type: Optional[str] = None
    selected_acts: Optional[List[str]] = None
    state_snapshot: Optional[Dict[str, Any]] = None
    project_plan: Optional[Dict[str, Any]] = None
    decision_metadata: Optional[Dict[str, Any]] = None
    metrics: Optional[Dict[str, Any]] = None
    performance_metrics: Optional[Dict[str, Any]] = None  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’è¿½åŠ 

async def optimized_chat_with_ai(
    chat_data,
    current_user: int,
    supabase,
    llm_client,
    conversation_orchestrator,
    ENABLE_CONVERSATION_AGENT: bool,
    MAX_CHAT_MESSAGE_LENGTH: int = 2000
):
    """
    æœ€é©åŒ–ç‰ˆ chat_with_ai ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    ä¸¦åˆ—å‡¦ç†ã¨éåŒæœŸå‡¦ç†ã‚’æ´»ç”¨
    
    Args:
        chat_data: ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿
        current_user: ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        supabase: Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        llm_client: LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆäº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
        conversation_orchestrator: å¯¾è©±ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼
        ENABLE_CONVERSATION_AGENT: å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœ‰åŠ¹åŒ–ãƒ•ãƒ©ã‚°
        MAX_CHAT_MESSAGE_LENGTH: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ€å¤§é•·
        
    Returns:
        OptimizedChatResponse
    """
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬é–‹å§‹
    start_time = time.time()
    metrics = {
        "db_fetch_time": 0,
        "llm_response_time": 0,
        "db_save_time": 0,
        "total_time": 0
    }
    
    try:
        # åŸºæœ¬æ¤œè¨¼
        if not supabase:
            raise HTTPException(status_code=500, detail="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        if llm_client is None and not ENABLE_CONVERSATION_AGENT:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é•·æ¤œè¨¼
        if chat_data.message and len(chat_data.message) > MAX_CHAT_MESSAGE_LENGTH:
            raise HTTPException(status_code=400, detail="Message too long")
        
        # ãƒ˜ãƒ«ãƒ‘ãƒ¼åˆæœŸåŒ–
        db_helper = AsyncDatabaseHelper(supabase)
        context_builder = AsyncProjectContextBuilder(db_helper)
        async_llm = get_async_llm_client()
        
        # ãƒšãƒ¼ã‚¸IDã®æ±ºå®šï¼ˆChatMessageã‹ã‚‰pageé–¢é€£ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå‰Šé™¤ã•ã‚ŒãŸãŸã‚å›ºå®šå€¤ã‚’ä½¿ç”¨ï¼‰
        page_id = "general"
        
        # ====================
        # Step 1: ä¸¦åˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—
        # ====================
        db_fetch_start = time.time()
        
        # conversationã®å–å¾—/ä½œæˆï¼ˆæ—¢å­˜ã®é–¢æ•°ã‚’éåŒæœŸåŒ–ï¼‰
        conversation_id = await asyncio.to_thread(
            lambda: get_or_create_conversation_sync(supabase, current_user, page_id)
        )
        
        # å±¥æ­´å–å¾—æ•°ã®å‹•çš„èª¿æ•´ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ï¼‰
        history_limit = 20  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ¸›ã‚‰ã™
        if chat_data.message and len(chat_data.message) > 500:
            history_limit = 50  # é•·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã¯å¢—ã‚„ã™
        elif ENABLE_CONVERSATION_AGENT and conversation_orchestrator:
            history_limit = 100  # å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½¿ç”¨æ™‚ã¯æœ€å¤§
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨å±¥æ­´ã‚’ä¸¦åˆ—å–å¾—
        project_id, project_context, project, conversation_history = await parallel_fetch_context_and_history(
            db_helper=db_helper,
            context_builder=context_builder,
            page_id=page_id,
            conversation_id=conversation_id,
            user_id=current_user,
            history_limit=history_limit
        )
        
        metrics["db_fetch_time"] = time.time() - db_fetch_start
        logger.info(f"ğŸ“Š DBå–å¾—æ™‚é–“: {metrics['db_fetch_time']:.2f}ç§’ (å±¥æ­´: {len(conversation_history)}ä»¶)")
        
        # ====================
        # Step 2: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
        # ====================
        system_prompt_with_context = build_system_prompt(project_context)
        messages = build_message_history(system_prompt_with_context, conversation_history, chat_data.message)
        
        # ====================
        # Step 3: LLMå¿œç­”ç”Ÿæˆï¼ˆä¸¦åˆ—åŒ–å¯èƒ½ãªå ´åˆï¼‰
        # ====================
        llm_start = time.time()
        agent_payload = {}
        
        if ENABLE_CONVERSATION_AGENT and conversation_orchestrator is not None:
            # å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†
            try:
                agent_result = await process_with_conversation_agent(
                    conversation_orchestrator,
                    chat_data.message,
                    conversation_history,
                    project,
                    project_id,
                    current_user,
                    conversation_id
                )
                response = agent_result["response"]
                agent_payload = extract_agent_payload(agent_result)
                
                # followupsãŒã‚ã‚‹å ´åˆ
                if agent_result.get("followups"):
                    followup_text = "\n\n**æ¬¡ã«ã§ãã‚‹ã“ã¨:**\n" + "\n".join([f"â€¢ {f}" for f in agent_result["followups"][:3]])
                    response += followup_text
                
                logger.info(f"âœ… å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†å®Œäº†: {agent_result.get('support_type')}")
                
            except Exception as e:
                logger.error(f"âŒ å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: éåŒæœŸLLMå‘¼ã³å‡ºã—
                response = await async_llm.generate_with_fallback(messages)
        else:
            # é€šå¸¸ã®éåŒæœŸLLMå‘¼ã³å‡ºã—
            response = await async_llm.generate_response_async(messages)
        
        metrics["llm_response_time"] = time.time() - llm_start
        logger.info(f"ğŸ“Š LLMå¿œç­”æ™‚é–“: {metrics['llm_response_time']:.2f}ç§’")
        
        # ====================
        # Step 4: ãƒ­ã‚°ã®ä¸¦åˆ—ä¿å­˜
        # ====================
        save_start = time.time()
        
        # context_dataæ§‹ç¯‰
        user_context_data = build_context_data(
            project_id=project_id,
            project=project,
            #memo_content=chat_data.memo_content
        )
        
        ai_context_data = build_ai_context_data(
            project_context=project_context,
            project_id=project_id,
            agent_payload=agent_payload,
            is_agent=bool(agent_payload)
        )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
        user_msg_data = {
            "user_id": current_user,
            "page_id": page_id,
            "sender": "user",
            "message": chat_data.message,
            "conversation_id": conversation_id,
            "context_data": user_context_data
        }
        
        ai_msg_data = {
            "user_id": current_user,
            "page_id": page_id,
            "sender": "assistant",
            "message": response,
            "conversation_id": conversation_id,
            "context_data": ai_context_data
        }
        
        # ä¸¦åˆ—ä¿å­˜
        user_saved, ai_saved = await parallel_save_chat_logs(
            db_helper,
            user_msg_data,
            ai_msg_data
        )
        
        # conversation timestampã®æ›´æ–°ï¼ˆéãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
        asyncio.create_task(
            update_conversation_timestamp_async(db_helper, conversation_id)
        )
        
        metrics["db_save_time"] = time.time() - save_start
        logger.info(f"ğŸ“Š DBä¿å­˜æ™‚é–“: {metrics['db_save_time']:.2f}ç§’")
        
        # ====================
        # Step 5: ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰
        # ====================
        metrics["total_time"] = time.time() - start_time
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å«ã‚ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹
        return OptimizedChatResponse(
            response=response,
            timestamp=datetime.now(timezone.utc).isoformat(),
            token_usage=None,  # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¯å‰Šé™¤
            context_metadata={"has_project_context": bool(project_context)},
            performance_metrics=metrics,
            **agent_payload
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"Chat API Error: {str(e)}\nTraceback: {traceback.format_exc()}")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿”ã™
        metrics["total_time"] = time.time() - start_time
        metrics["error"] = str(e)
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"AIå¿œç­”ã®ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


# =====================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤
# =====================================

def get_or_create_conversation_sync(supabase, user_id: int, page_id: str) -> str:
    """æ—¢å­˜ã®get_or_create_conversationé–¢æ•°ã®åŒæœŸç‰ˆ"""
    try:
        existing_conv = supabase.table("chat_conversations").select("*").eq("user_id", user_id).eq("page_id", page_id).execute()
        
        if existing_conv.data:
            return existing_conv.data[0]["id"]
        else:
            title = f"{page_id}ã§ã®ç›¸è«‡"
            new_conv_data = {
                "user_id": user_id,
                "title": title,
                "page_id": page_id
            }
            new_conv = supabase.table("chat_conversations").insert(new_conv_data).execute()
            return new_conv.data[0]["id"] if new_conv.data else None
    except Exception as e:
        logger.error(f"conversationå–å¾—/ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        raise


def build_system_prompt(project_context: Optional[str]) -> str:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
    from prompt.prompt import system_prompt
    
    system_prompt_with_context = system_prompt
    if project_context:
        system_prompt_with_context += project_context
        logger.info(f"âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’è¿½åŠ ")
    
    return system_prompt_with_context


def build_message_history(
    system_prompt: str, 
    conversation_history: List[Dict[str, Any]], 
    user_message: str
) -> List[Dict[str, str]]:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’æ§‹ç¯‰"""
    messages = [{"role": "system", "content": system_prompt}]
    
    if conversation_history:
        for history_msg in conversation_history:
            role = "user" if history_msg["sender"] == "user" else "assistant"
            messages.append({"role": role, "content": history_msg["message"]})
    
    messages.append({"role": "user", "content": user_message})
    return messages


def build_context_data(
    project_id: Optional[int],
    project: Optional[Dict[str, Any]]
    #memo_content: Optional[str]
) -> Dict[str, Any]:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰"""
    context_data = {"timestamp": datetime.now(timezone.utc).isoformat()}
    
    #if memo_content:
    #   context_data["memo_content"] = memo_content[:500]
    
    if project_id:
        context_data["project_id"] = project_id
    
    if project:
        context_data["project_info"] = {
            "theme": project.get('theme'),
            "question": project.get('question'),
            "hypothesis": project.get('hypothesis')
        }
    
    return context_data


def build_ai_context_data(
    project_context: Optional[str],
    project_id: Optional[int],
    agent_payload: Dict[str, Any],
    is_agent: bool
) -> Dict[str, Any]:
    """AIã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰"""
    context_data = {
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "has_project_context": bool(project_context)
    }
    
    if project_id:
        context_data["project_id"] = project_id
    
    if is_agent:
        context_data["conversation_agent"] = True
        context_data.update(agent_payload)
    
    return context_data


async def process_with_conversation_agent(
    orchestrator,
    user_message: str,
    conversation_history: List[Dict[str, Any]],
    project: Optional[Dict[str, Any]],
    project_id: Optional[int],
    user_id: int,
    conversation_id: str
) -> Dict[str, Any]:
    """å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã®å‡¦ç†ã‚’éåŒæœŸåŒ–"""
    # å±¥æ­´ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›
    agent_history = []
    for history_msg in conversation_history:
        sender = "user" if history_msg["sender"] == "user" else "assistant"
        agent_history.append({
            "sender": sender,
            "message": history_msg["message"]
        })
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›
    agent_project_context = None
    if project:
        agent_project_context = {
            "theme": project.get('theme'),
            "question": project.get('question'),
            "hypothesis": project.get('hypothesis'),
            "id": project_id
        }
    
    # å¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ï¼ˆéåŒæœŸãƒ©ãƒƒãƒ—ï¼‰
    return await asyncio.to_thread(
        orchestrator.process_turn,
        user_message=user_message,
        conversation_history=agent_history,
        project_context=agent_project_context,
        user_id=user_id,
        conversation_id=conversation_id
    )


def extract_agent_payload(agent_result: Dict[str, Any]) -> Dict[str, Any]:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœã‹ã‚‰ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
    return {
        "support_type": agent_result.get("support_type"),
        "selected_acts": agent_result.get("selected_acts"),
        "state_snapshot": agent_result.get("state_snapshot"),
        "project_plan": agent_result.get("project_plan"),
        "decision_metadata": agent_result.get("decision_metadata"),
        "metrics": agent_result.get("metrics"),
    }


async def update_conversation_timestamp_async(db_helper: AsyncDatabaseHelper, conversation_id: str):
    """conversation timestampã‚’éåŒæœŸã§æ›´æ–°ï¼ˆã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼‰"""
    try:
        await asyncio.to_thread(
            lambda: db_helper.supabase.table("chat_conversations").update({
                "updated_at": datetime.now().isoformat()
            }).eq("id", conversation_id).execute()
        )
    except Exception as e:
        logger.warning(f"conversation timestampæ›´æ–°ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")