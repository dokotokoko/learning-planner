"""
main.pyã¸ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†æ©Ÿèƒ½çµ±åˆãƒ‘ãƒƒãƒ
æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’æœ€å°é™ã®å¤‰æ›´ã§æ‹¡å¼µ
"""
import os
import logging
from typing import List, Dict, Optional, Any, Tuple
from datetime import datetime, timezone
import asyncio

from context_manager import ContextManager, ContextMetrics
from embedding_utils import EmbeddingClient, SemanticSearch

logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†æ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ¶å¾¡
ENABLE_CONTEXT_MANAGER = os.environ.get("ENABLE_CONTEXT_MANAGER", "false").lower() == "true"
ENABLE_EMBEDDINGS = os.environ.get("ENABLE_EMBEDDINGS", "false").lower() == "true"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆèµ·å‹•æ™‚ã«åˆæœŸåŒ–ï¼‰
context_manager: Optional[ContextManager] = None
embedding_client: Optional[EmbeddingClient] = None
semantic_search: Optional[SemanticSearch] = None


async def initialize_context_system(supabase_client=None):
    """
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
    main.pyã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«å‘¼ã³å‡ºã™
    """
    global context_manager, embedding_client, semantic_search
    
    if not ENABLE_CONTEXT_MANAGER:
        logger.info("â„¹ï¸ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™")
        return False
    
    try:
        logger.info("ğŸš€ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã‚’é–‹å§‹")
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ï¼ˆtiktokenä½¿ç”¨æ™‚ã¯ã“ã“ã§åˆæœŸåŒ–ï¼‰
        token_counter = None
        try:
            import tiktoken
            encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
            token_counter = lambda text: len(encoding.encode(text))
            logger.info("âœ… tiktoken ã‚’ä½¿ç”¨ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–")
        except ImportError:
            logger.warning("âš ï¸ tiktoken ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç°¡æ˜“ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™")
        
        # åŸ‹ã‚è¾¼ã¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆPhase 2ï¼‰
        if ENABLE_EMBEDDINGS:
            provider = os.environ.get("EMBEDDING_PROVIDER", "openai")
            embedding_client = EmbeddingClient(provider=provider)
            semantic_search = SemanticSearch(embedding_client, supabase_client)
            logger.info(f"âœ… åŸ‹ã‚è¾¼ã¿æ©Ÿèƒ½ã‚’åˆæœŸåŒ–: {provider}")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        context_manager = ContextManager(
            supabase_client=supabase_client,
            embedding_client=embedding_client,
            token_counter=token_counter
        )
        
        logger.info("ğŸ‰ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ã‚¹ãƒ†ãƒ ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã‚‹ãŒã€ã‚¢ãƒ—ãƒªã¯ç¶šè¡Œ
        context_manager = None
        embedding_client = None
        semantic_search = None
        return False


async def build_enhanced_messages(
    user_message: str,
    conversation_id: str,
    conversation_history: List[Dict[str, Any]],
    system_prompt: str
) -> Tuple[List[Dict[str, str]], Optional[ContextMetrics]]:
    """
    å¼·åŒ–ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰
    
    ã“ã®é–¢æ•°ã‚’main.pyã‹ã‚‰å‘¼ã³å‡ºã—ã¦ã€æ—¢å­˜ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰ã‚’ç½®ãæ›ãˆã‚‹
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ãŒç„¡åŠ¹ãªå ´åˆã¯å¾“æ¥ã®æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ãŒæœ‰åŠ¹ãªå ´åˆ
    if context_manager:
        try:
            messages, metrics = await context_manager.build_context(
                user_message=user_message,
                conversation_id=conversation_id,
                system_prompt=system_prompt,
                conversation_history=conversation_history
            )
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            if metrics:
                logger.info(f"ğŸ“Š ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
                logger.info(f"   ç·ãƒˆãƒ¼ã‚¯ãƒ³: {metrics.total_tokens}")
                logger.info(f"   åœ§ç¸®ç‡: {metrics.compression_ratio:.2f}")
                if metrics.retrieval_hits > 0:
                    logger.info(f"   æ¤œç´¢ãƒ’ãƒƒãƒˆ: {metrics.retrieval_hits}")
            
            return messages, metrics
            
        except Exception as e:
            logger.error(f"âŒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å¾“æ¥æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    # å¾“æ¥ã®æ–¹å¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    messages = build_legacy_messages(
        user_message,
        conversation_history,
        system_prompt
    )
    
    return messages, None


def build_legacy_messages(
    user_message: str,
    conversation_history: List[Dict[str, Any]],
    system_prompt: str
) -> List[Dict[str, str]]:
    """
    å¾“æ¥ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰æ–¹å¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    main.pyã®æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ä½¿ç”¨
    """
    messages = [{"role": "system", "content": system_prompt}]
    
    if conversation_history:
        for history_msg in conversation_history:
            role = "user" if history_msg["sender"] == "user" else "assistant"
            messages.append({"role": role, "content": history_msg["message"]})
    
    messages.append({"role": "user", "content": user_message})
    
    return messages


async def save_message_with_embedding(
    supabase_client,
    message_data: Dict[str, Any],
    generate_embedding: bool = True
) -> bool:
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ã—ã€å¿…è¦ã«å¿œã˜ã¦åŸ‹ã‚è¾¼ã¿ã‚‚ç”Ÿæˆ
    
    Phase 2ã§ä½¿ç”¨: chat_logsãƒ†ãƒ¼ãƒ–ãƒ«ã«åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚‚ä¿å­˜
    """
    try:
        # åŸºæœ¬çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
        result = await asyncio.to_thread(
            lambda: supabase_client.table("chat_logs").insert(message_data).execute()
        )
        
        if not result.data:
            return False
        
        message_id = result.data[0]["id"]
        
        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
        if ENABLE_EMBEDDINGS and embedding_client and generate_embedding:
            try:
                message_text = message_data.get("message", "")
                if message_text:
                    # éåŒæœŸã§åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
                    embedding = await embedding_client.generate_embedding(message_text)
                    
                    # åŸ‹ã‚è¾¼ã¿ã‚’DBã«ä¿å­˜
                    # æ³¨: pgvectorã®å ´åˆã¯é…åˆ—ã‚’ãã®ã¾ã¾ä¿å­˜å¯èƒ½
                    embedding_data = {
                        "embedding": embedding.tolist()
                    }
                    
                    await asyncio.to_thread(
                        lambda: supabase_client.table("chat_logs")
                        .update(embedding_data)
                        .eq("id", message_id)
                        .execute()
                    )
                    
                    logger.info(f"âœ… åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆãƒ»ä¿å­˜: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ID={message_id}")
                    
            except Exception as e:
                # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã«å¤±æ•—ã—ã¦ã‚‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ã¯æˆåŠŸã¨ã™ã‚‹
                logger.warning(f"âš ï¸ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ä¿å­˜æ¸ˆã¿ï¼‰: {e}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False


async def search_relevant_context(
    query: str,
    conversation_id: str,
    k: int = 3
) -> List[Dict[str, Any]]:
    """
    é–¢é€£ã™ã‚‹éå»ã®æ–‡è„ˆã‚’æ¤œç´¢
    
    Phase 2ã§ä½¿ç”¨: æ„å‘³çš„é¡ä¼¼æ¤œç´¢ã‚’å®Ÿè¡Œ
    """
    if not semantic_search:
        return []
    
    try:
        results = await semantic_search.search(
            query=query,
            conversation_id=conversation_id,
            k=k,
            use_mmr=True
        )
        
        # çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
        context_items = []
        for result in results:
            context_items.append({
                "id": result.id,
                "message": result.text,
                "score": result.score,
                "metadata": result.metadata
            })
        
        return context_items
        
    except Exception as e:
        logger.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []


async def update_conversation_summary(
    supabase_client,
    conversation_id: str,
    conversation_history: List[Dict[str, Any]],
    force: bool = False
) -> bool:
    """
    ä¼šè©±ã®è¦ç´„ã‚’æ›´æ–°
    
    Phase 2ã§ä½¿ç”¨: LLMã‚’ä½¿ã£ã¦è¦ç´„ã‚’ç”Ÿæˆ
    """
    if not context_manager:
        return False
    
    try:
        turn_count = len(conversation_history)
        updated = await context_manager.rotate_summary_if_needed(
            conversation_id=conversation_id,
            turn_count=turn_count,
            force=force
        )
        
        if updated:
            logger.info(f"âœ… ä¼šè©±è¦ç´„ã‚’æ›´æ–°: {conversation_id[:8]}...")
        
        return updated
        
    except Exception as e:
        logger.error(f"âŒ è¦ç´„æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return False


# ==================================================
# main.pyã¸ã®çµ±åˆæ–¹æ³•
# ==================================================
"""
main.pyã«ä»¥ä¸‹ã®å¤‰æ›´ã‚’è¿½åŠ :

1. ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¿½åŠ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å…ˆé ­ä»˜è¿‘ï¼‰:
```python
from context_integration import (
    initialize_context_system,
    build_enhanced_messages,
    save_message_with_embedding,
    ENABLE_CONTEXT_MANAGER
)
```

2. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®åˆæœŸåŒ–ï¼ˆ@app.on_event("startup")å†…ï¼‰:
```python
@app.on_event("startup")
async def startup_event():
    # æ—¢å­˜ã®åˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰...
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    if ENABLE_CONTEXT_MANAGER:
        await initialize_context_system(supabase)
```

3. /chatã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å¤‰æ›´ï¼ˆ754-766è¡Œç›®ä»˜è¿‘ï¼‰:
```python
# æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰:
# messages = [{"role": "system", "content": dev_system_prompt}]
# if conversation_history:
#     for history_msg in conversation_history:
#         role = "user" if history_msg["sender"] == "user" else "assistant"
#         messages.append({"role": role, "content": history_msg["message"]})
# messages.append({"role": "user", "content": user_message})

# æ–°ã—ã„ã‚³ãƒ¼ãƒ‰:
messages, context_metrics = await build_enhanced_messages(
    user_message=user_message,
    conversation_id=conversation_id,
    conversation_history=conversation_history,
    system_prompt=dev_system_prompt
)

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å¿œç­”ã«å«ã‚ã‚‹å ´åˆ
if context_metrics:
    # context_metadataã«è¿½åŠ 
    context_metadata = {
        "tokens_used": context_metrics.total_tokens,
        "compression_ratio": context_metrics.compression_ratio,
        # ... ä»–ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    }
```

4. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜æ™‚ã®å¤‰æ›´ï¼ˆ779è¡Œç›®ä»˜è¿‘ï¼‰:
```python
# æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰:
# await asyncio.to_thread(lambda: supabase.table("chat_logs").insert(user_message_data).execute())

# æ–°ã—ã„ã‚³ãƒ¼ãƒ‰:
if ENABLE_CONTEXT_MANAGER:
    await save_message_with_embedding(supabase, user_message_data, generate_embedding=True)
else:
    await asyncio.to_thread(lambda: supabase.table("chat_logs").insert(user_message_data).execute())
```

ã“ã‚Œã‚‰ã®å¤‰æ›´ã«ã‚ˆã‚Šã€ç’°å¢ƒå¤‰æ•°ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†æ©Ÿèƒ½ã®ON/OFFã‚’åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚
"""