"""
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ®µéšçš„ã«å„æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
"""
import os
import sys
import asyncio
import logging
from datetime import datetime
from typing import List, Dict, Any

# ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
os.environ["ENABLE_CONTEXT_MANAGER"] = "true"
os.environ["TOKEN_BUDGET_IN"] = "1000"  # ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã„å€¤
os.environ["N_RECENT"] = "5"
os.environ["K_RETRIEVE"] = "3"

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from context_manager import ContextManager, ContextSection
from embedding_utils import EmbeddingClient, SemanticSearch, SearchResult
from context_integration import (
    initialize_context_system,
    build_enhanced_messages,
    build_legacy_messages
)

def create_test_history() -> List[Dict[str, Any]]:
    """ãƒ†ã‚¹ãƒˆç”¨ã®ä¼šè©±å±¥æ­´ã‚’ä½œæˆ"""
    return [
        {
            "id": 1,
            "sender": "user",
            "message": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶ã‚’æ•™ãˆã¦ãã ã•ã„",
            "created_at": "2024-01-01T10:00:00Z"
        },
        {
            "id": 2,
            "sender": "assistant",
            "message": "ä»¥ä¸‹ã®è¦ä»¶ã§é€²ã‚ã¾ã™ï¼š1. ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ 2. é«˜é€Ÿãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ 3. ã‚»ã‚­ãƒ¥ã‚¢ãªå®Ÿè£…",
            "created_at": "2024-01-01T10:01:00Z"
        },
        {
            "id": 3,
            "sender": "user",
            "message": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã«ã¤ã„ã¦ç›¸è«‡ã—ãŸã„ã§ã™",
            "created_at": "2024-01-01T10:05:00Z"
        },
        {
            "id": 4,
            "sender": "assistant",
            "message": "æ­£è¦åŒ–ã‚’é©åˆ‡ã«è¡Œã„ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æœ€é©åŒ–ã—ã¾ã—ã‚‡ã†",
            "created_at": "2024-01-01T10:06:00Z"
        },
        {
            "id": 5,
            "sender": "user",
            "message": "äº†è§£ã—ã¾ã—ãŸ",
            "created_at": "2024-01-01T10:07:00Z"
        },
        {
            "id": 6,
            "sender": "assistant",
            "message": "ä½•ã‹ä»–ã«è³ªå•ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            "created_at": "2024-01-01T10:08:00Z"
        },
        {
            "id": 7,
            "sender": "user",
            "message": "APIè¨­è¨ˆã®æ–¹é‡ã‚’æ±ºã‚ãŸã„ã§ã™",
            "created_at": "2024-01-01T10:10:00Z"
        },
        {
            "id": 8,
            "sender": "assistant",
            "message": "RESTful APIã§ã€OpenAPIä»•æ§˜ã«æº–æ‹ ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™",
            "created_at": "2024-01-01T10:11:00Z"
        }
    ]

async def test_phase1_basic_context():
    """Phase 1: åŸºæœ¬çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*50)
    print("Phase 1: åŸºæœ¬çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã®ãƒ†ã‚¹ãƒˆ")
    print("="*50)
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    context_manager = ContextManager()
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ä¼šè©±å±¥æ­´
    history = create_test_history()
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
    messages, metrics = await context_manager.build_context(
        user_message="å‰ã«è©±ã—ãŸè¦ä»¶ã«ã¤ã„ã¦ç¢ºèªã—ãŸã„ã§ã™",
        conversation_id="test-conversation-001",
        system_prompt="ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
        conversation_history=history
    )
    
    # çµæœè¡¨ç¤º
    print("\nğŸ“Š ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:")
    print("-" * 40)
    
    for i, msg in enumerate(messages):
        role = msg["role"]
        content = msg["content"][:200] + "..." if len(msg["content"]) > 200 else msg["content"]
        print(f"\n[{i+1}] Role: {role}")
        print(f"Content: {content}")
    
    print("\nğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
    print("-" * 40)
    print(f"ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {metrics.total_tokens}")
    print(f"ã‚·ã‚¹ãƒ†ãƒ : {metrics.system_tokens}")
    print(f"è¦ç´„: {metrics.summary_tokens}")
    print(f"ç›´è¿‘: {metrics.recent_tokens}")
    print(f"åœ§ç¸®ç‡: {metrics.compression_ratio:.2f}")
    
    return messages, metrics

async def test_phase2_embeddings():
    """Phase 2: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã¨æ¤œç´¢ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*50)
    print("Phase 2: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã¨æ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ")
    print("="*50)
    
    # åŸ‹ã‚è¾¼ã¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
    embedding_client = EmbeddingClient(provider="openai")
    
    # ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
    test_texts = [
        "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶å®šç¾©ã«ã¤ã„ã¦",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã®æœ€é©åŒ–",
        "APIã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–",
        "ä»Šæ—¥ã®å¤©æ°—ã¯ã©ã†ã§ã™ã‹",  # ç„¡é–¢ä¿‚ãªæ–‡
        "è¦ä»¶ã«å¾“ã£ãŸå®Ÿè£…ã‚’é€²ã‚ã¾ã™"
    ]
    
    print("\nğŸ”¬ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
    print("-" * 40)
    
    embeddings = []
    for text in test_texts:
        embedding = await embedding_client.generate_embedding(text)
        embeddings.append(embedding)
        print(f"âœ… '{text[:30]}...' â†’ ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {embedding.shape}")
    
    # é¡ä¼¼åº¦è¨ˆç®—
    print("\nğŸ“ é¡ä¼¼åº¦è¨ˆç®—ãƒ†ã‚¹ãƒˆ:")
    print("-" * 40)
    
    query_text = "è¦ä»¶å®šç¾©ã®ç¢ºèª"
    query_embedding = await embedding_client.generate_embedding(query_text)
    
    print(f"ã‚¯ã‚¨ãƒª: '{query_text}'")
    print("\né¡ä¼¼åº¦ã‚¹ã‚³ã‚¢:")
    
    similarities = []
    for i, (text, emb) in enumerate(zip(test_texts, embeddings)):
        similarity = embedding_client.cosine_similarity(query_embedding, emb)
        similarities.append((i, text, similarity))
        print(f"  [{i}] {similarity:.3f} - {text[:40]}...")
    
    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    similarities.sort(key=lambda x: x[2], reverse=True)
    
    print("\nğŸ† Top 3 é¡ä¼¼æ–‡æ›¸:")
    for i, (idx, text, score) in enumerate(similarities[:3]):
        print(f"  {i+1}. (ã‚¹ã‚³ã‚¢: {score:.3f}) {text}")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
    stats = embedding_client.get_cache_stats()
    print(f"\nğŸ“Š ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ: {stats}")

async def test_phase2_semantic_search():
    """Phase 2: æ„å‘³æ¤œç´¢ã¨MMRã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*50)
    print("Phase 2: æ„å‘³æ¤œç´¢ã¨MMRã®ãƒ†ã‚¹ãƒˆ")
    print("="*50)
    
    # åˆæœŸåŒ–
    embedding_client = EmbeddingClient(provider="openai")
    semantic_search = SemanticSearch(embedding_client)
    
    # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    print("\nğŸ” æ„å‘³æ¤œç´¢ãƒ†ã‚¹ãƒˆ:")
    print("-" * 40)
    
    results = await semantic_search.search(
        query="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶ã«ã¤ã„ã¦",
        conversation_id="test-conversation-001",
        k=3,
        use_mmr=True
    )
    
    print(f"æ¤œç´¢çµæœ: {len(results)}ä»¶")
    for i, result in enumerate(results):
        print(f"\n[{i+1}] ã‚¹ã‚³ã‚¢: {result.score:.3f}")
        print(f"  å†…å®¹: {result.text[:100]}...")
        print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {result.metadata}")
    
    # ãƒˆãƒ”ãƒƒã‚¯åˆ‡æ›¿æ¤œå‡º
    print("\nğŸ”„ ãƒˆãƒ”ãƒƒã‚¯åˆ‡æ›¿æ¤œå‡ºãƒ†ã‚¹ãƒˆ:")
    print("-" * 40)
    
    current_text = "å¤©æ°—äºˆå ±ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"  # æ–°ã—ã„ãƒˆãƒ”ãƒƒã‚¯
    recent_texts = [
        "APIã®è¨­è¨ˆæ–¹é‡",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ­£è¦åŒ–",
        "è¦ä»¶å®šç¾©ã®ç¢ºèª"
    ]
    
    current_emb = await embedding_client.generate_embedding(current_text)
    recent_embs = [
        await embedding_client.generate_embedding(text)
        for text in recent_texts
    ]
    
    is_switch = semantic_search.detect_topic_switch(
        current_emb,
        recent_embs,
        threshold=0.8
    )
    
    print(f"ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: '{current_text}'")
    print(f"ãƒˆãƒ”ãƒƒã‚¯åˆ‡æ›¿æ¤œå‡º: {'ã¯ã„ âœ…' if is_switch else 'ã„ã„ãˆ âŒ'}")

async def test_integration():
    """çµ±åˆãƒ†ã‚¹ãƒˆ: build_enhanced_messagesé–¢æ•°"""
    print("\n" + "="*50)
    print("çµ±åˆãƒ†ã‚¹ãƒˆ: build_enhanced_messages")
    print("="*50)
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    await initialize_context_system()
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
    user_message = "å‰å›ã®è¦ä»¶å®šç¾©ã«ã¤ã„ã¦ç¢ºèªã•ã›ã¦ãã ã•ã„"
    conversation_id = "test-conv-002"
    history = create_test_history()
    system_prompt = "ã‚ãªãŸã¯æŠ€è¡“ã‚µãƒãƒ¼ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    
    # å¼·åŒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
    print("\nğŸš€ å¼·åŒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰:")
    print("-" * 40)
    
    messages, metrics = await build_enhanced_messages(
        user_message=user_message,
        conversation_id=conversation_id,
        conversation_history=history,
        system_prompt=system_prompt
    )
    
    print(f"ç”Ÿæˆã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(messages)}")
    
    if metrics:
        print(f"\nğŸ“Š ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        print(f"  ç·ãƒˆãƒ¼ã‚¯ãƒ³: {metrics.total_tokens}")
        print(f"  åœ§ç¸®ç‡: {metrics.compression_ratio:.2f}")
    else:
        print("\nâš ï¸ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãªã—ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¢ãƒ¼ãƒ‰ï¼‰")
    
    # ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒ
    print("\nğŸ“Š ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒ:")
    print("-" * 40)
    
    legacy_messages = build_legacy_messages(
        user_message=user_message,
        conversation_history=history,
        system_prompt=system_prompt
    )
    
    print(f"ãƒ¬ã‚¬ã‚·ãƒ¼: {len(legacy_messages)}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
    print(f"å¼·åŒ–ç‰ˆ: {len(messages)}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
    
    # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¦‚ç®—æ¯”è¼ƒ
    legacy_tokens = sum(len(msg["content"]) // 4 for msg in legacy_messages)
    enhanced_tokens = metrics.total_tokens if metrics else sum(len(msg["content"]) // 4 for msg in messages)
    
    print(f"\nãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆæ¦‚ç®—ï¼‰:")
    print(f"  ãƒ¬ã‚¬ã‚·ãƒ¼: ~{legacy_tokens}")
    print(f"  å¼·åŒ–ç‰ˆ: {enhanced_tokens}")
    print(f"  å‰Šæ¸›ç‡: {(1 - enhanced_tokens/legacy_tokens)*100:.1f}%")

async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–¢æ•°"""
    print("\n" + "ğŸ¯"*25)
    print(" ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("ğŸ¯"*25)
    
    try:
        # Phase 1ãƒ†ã‚¹ãƒˆ
        await test_phase1_basic_context()
        
        # Phase 2ãƒ†ã‚¹ãƒˆï¼ˆåŸ‹ã‚è¾¼ã¿æ©Ÿèƒ½ãŒæœ‰åŠ¹ãªå ´åˆï¼‰
        if os.environ.get("ENABLE_EMBEDDINGS", "false").lower() == "true":
            await test_phase2_embeddings()
            await test_phase2_semantic_search()
        else:
            print("\nâš ï¸ Phase 2ãƒ†ã‚¹ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆENABLE_EMBEDDINGS=falseï¼‰")
        
        # çµ±åˆãƒ†ã‚¹ãƒˆ
        await test_integration()
        
        print("\n" + "âœ…"*25)
        print(" ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("âœ…"*25)
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    asyncio.run(main())