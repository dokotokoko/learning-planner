"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
å˜ä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ vs ãƒ—ãƒ¼ãƒ« vs è² è·åˆ†æ•£ã®æ€§èƒ½æ¸¬å®š
"""

import asyncio
import time
import statistics
import logging
from typing import List, Dict, Any, Tuple
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from module.llm_api import learning_plannner
from llm_pool_manager import get_llm_pool
from load_balancer import get_load_balancer, LoadBalanceStrategy

logger = logging.getLogger(__name__)


@dataclass
class BenchmarkResult:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ"""
    method: str
    total_time: float
    avg_response_time: float
    median_response_time: float
    min_response_time: float
    max_response_time: float
    success_rate: float
    requests_per_second: float
    error_count: int
    timeout_count: int
    concurrent_users: int


class PerformanceBenchmark:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, test_message: str = "ã“ã‚“ã«ã¡ã¯ã€å­¦ç¿’ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚"):
        self.test_message = test_message
        self.test_messages = [
            {"role": "system", "content": "ã‚ãªãŸã¯å­¦ç¿’æ”¯æ´AIã§ã™ã€‚"},
            {"role": "user", "content": test_message}
        ]
    
    async def benchmark_single_instance(self, concurrent_users: int = 20, timeout: float = 30.0) -> BenchmarkResult:
        """å˜ä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ–¹å¼ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info(f"ğŸ” å˜ä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ–¹å¼ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹ (ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {concurrent_users})")
        
        # å˜ä¸€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
        client = learning_plannner()
        
        async def single_request(request_id: int) -> Tuple[float, bool, str]:
            start_time = time.time()
            try:
                # åŒæœŸé–¢æ•°ã‚’éåŒæœŸã§å®Ÿè¡Œï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
                response = await asyncio.wait_for(
                    asyncio.to_thread(client.generate_response, self.test_messages),
                    timeout=timeout
                )
                response_time = time.time() - start_time
                return response_time, True, "success"
            except asyncio.TimeoutError:
                return time.time() - start_time, False, "timeout"
            except Exception as e:
                return time.time() - start_time, False, f"error: {str(e)}"
        
        # ä¸¦åˆ—å®Ÿè¡Œï¼ˆå®Ÿéš›ã¯ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã§é †æ¬¡å®Ÿè¡Œã•ã‚Œã‚‹ï¼‰
        start_time = time.time()
        tasks = [single_request(i) for i in range(concurrent_users)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        total_time = time.time() - start_time
        
        # çµæœåˆ†æ
        response_times = []
        success_count = 0
        error_count = 0
        timeout_count = 0
        
        for result in results:
            if isinstance(result, Exception):
                error_count += 1
                continue
            
            response_time, success, error_type = result
            response_times.append(response_time)
            
            if success:
                success_count += 1
            elif error_type == "timeout":
                timeout_count += 1
            else:
                error_count += 1
        
        return BenchmarkResult(
            method="Single Instance",
            total_time=total_time,
            avg_response_time=statistics.mean(response_times) if response_times else 0,
            median_response_time=statistics.median(response_times) if response_times else 0,
            min_response_time=min(response_times) if response_times else 0,
            max_response_time=max(response_times) if response_times else 0,
            success_rate=success_count / concurrent_users,
            requests_per_second=concurrent_users / total_time if total_time > 0 else 0,
            error_count=error_count,
            timeout_count=timeout_count,
            concurrent_users=concurrent_users
        )
    
    async def benchmark_connection_pool(self, concurrent_users: int = 20, pool_size: int = 10, timeout: float = 30.0) -> BenchmarkResult:
        """ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«æ–¹å¼ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info(f"ğŸ” ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«æ–¹å¼ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹ (ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {concurrent_users}, ãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚º: {pool_size})")
        
        # ãƒ—ãƒ¼ãƒ«ã‚’å–å¾—
        pool = await get_llm_pool(pool_size=pool_size)
        
        async def pool_request(request_id: int) -> Tuple[float, bool, str]:
            start_time = time.time()
            try:
                async with pool.get_async_client() as client:
                    response = await asyncio.wait_for(
                        client.generate_response_async(self.test_messages),
                        timeout=timeout
                    )
                    response_time = time.time() - start_time
                    return response_time, True, "success"
            except asyncio.TimeoutError:
                return time.time() - start_time, False, "timeout"
            except Exception as e:
                return time.time() - start_time, False, f"error: {str(e)}"
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        start_time = time.time()
        tasks = [pool_request(i) for i in range(concurrent_users)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        total_time = time.time() - start_time
        
        # çµæœåˆ†æ
        response_times = []
        success_count = 0
        error_count = 0
        timeout_count = 0
        
        for result in results:
            if isinstance(result, Exception):
                error_count += 1
                continue
            
            response_time, success, error_type = result
            response_times.append(response_time)
            
            if success:
                success_count += 1
            elif error_type == "timeout":
                timeout_count += 1
            else:
                error_count += 1
        
        return BenchmarkResult(
            method=f"Connection Pool (size={pool_size})",
            total_time=total_time,
            avg_response_time=statistics.mean(response_times) if response_times else 0,
            median_response_time=statistics.median(response_times) if response_times else 0,
            min_response_time=min(response_times) if response_times else 0,
            max_response_time=max(response_times) if response_times else 0,
            success_rate=success_count / concurrent_users,
            requests_per_second=concurrent_users / total_time if total_time > 0 else 0,
            error_count=error_count,
            timeout_count=timeout_count,
            concurrent_users=concurrent_users
        )
    
    async def benchmark_load_balancer(self, concurrent_users: int = 20, strategy: LoadBalanceStrategy = LoadBalanceStrategy.ADAPTIVE, timeout: float = 30.0) -> BenchmarkResult:
        """è² è·åˆ†æ•£æ–¹å¼ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info(f"ğŸ” è² è·åˆ†æ•£æ–¹å¼ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹ (ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {concurrent_users}, æˆ¦ç•¥: {strategy.value})")
        
        # è² è·åˆ†æ•£å™¨ã‚’å–å¾—
        load_balancer = await get_load_balancer(
            strategy=strategy,
            pool_configs=[
                {"pool_size": 8, "weight": 1.0},
                {"pool_size": 6, "weight": 0.8},
                {"pool_size": 4, "weight": 0.6}
            ]
        )
        
        async def lb_request(request_id: int) -> Tuple[float, bool, str]:
            start_time = time.time()
            try:
                async with await load_balancer.get_client(prefer_async=True) as client:
                    response = await asyncio.wait_for(
                        client.generate_response_async(self.test_messages),
                        timeout=timeout
                    )
                    response_time = time.time() - start_time
                    return response_time, True, "success"
            except asyncio.TimeoutError:
                return time.time() - start_time, False, "timeout"
            except Exception as e:
                return time.time() - start_time, False, f"error: {str(e)}"
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        start_time = time.time()
        tasks = [lb_request(i) for i in range(concurrent_users)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        total_time = time.time() - start_time
        
        # çµæœåˆ†æ
        response_times = []
        success_count = 0
        error_count = 0
        timeout_count = 0
        
        for result in results:
            if isinstance(result, Exception):
                error_count += 1
                continue
            
            response_time, success, error_type = result
            response_times.append(response_time)
            
            if success:
                success_count += 1
            elif error_type == "timeout":
                timeout_count += 1
            else:
                error_count += 1
        
        return BenchmarkResult(
            method=f"Load Balancer ({strategy.value})",
            total_time=total_time,
            avg_response_time=statistics.mean(response_times) if response_times else 0,
            median_response_time=statistics.median(response_times) if response_times else 0,
            min_response_time=min(response_times) if response_times else 0,
            max_response_time=max(response_times) if response_times else 0,
            success_rate=success_count / concurrent_users,
            requests_per_second=concurrent_users / total_time if total_time > 0 else 0,
            error_count=error_count,
            timeout_count=timeout_count,
            concurrent_users=concurrent_users
        )
    
    def print_benchmark_results(self, results: List[BenchmarkResult]):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’è¡¨ç¤º"""
        print("\n" + "="*80)
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ")
        print("="*80)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        print(f"{'æ–¹å¼':<20} {'ç·æ™‚é–“':<8} {'å¹³å‡å¿œç­”':<8} {'æˆåŠŸç‡':<8} {'RPS':<8} {'ã‚¨ãƒ©ãƒ¼':<6} {'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ':<10}")
        print("-"*80)
        
        # çµæœè¡¨ç¤º
        for result in results:
            print(f"{result.method:<20} "
                  f"{result.total_time:<8.2f} "
                  f"{result.avg_response_time:<8.2f} "
                  f"{result.success_rate:<8.1%} "
                  f"{result.requests_per_second:<8.1f} "
                  f"{result.error_count:<6} "
                  f"{result.timeout_count:<10}")
        
        print("\n" + "="*80)
        print("ğŸ“ˆ æ”¹å–„åŠ¹æœåˆ†æ")
        print("="*80)
        
        if len(results) >= 2:
            baseline = results[0]  # å˜ä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
            
            for i, result in enumerate(results[1:], 1):
                print(f"\n{result.method} vs {baseline.method}:")
                
                # ç·æ™‚é–“ã®æ”¹å–„
                time_improvement = (baseline.total_time - result.total_time) / baseline.total_time * 100
                print(f"  ğŸ“Š ç·å‡¦ç†æ™‚é–“: {time_improvement:+.1f}% ({'æ”¹å–„' if time_improvement > 0 else 'æ‚ªåŒ–'})")
                
                # RPSæ”¹å–„
                rps_improvement = (result.requests_per_second - baseline.requests_per_second) / baseline.requests_per_second * 100
                print(f"  ğŸš€ RPSå‘ä¸Š: {rps_improvement:+.1f}% ({result.requests_per_second:.1f} vs {baseline.requests_per_second:.1f})")
                
                # æˆåŠŸç‡æ”¹å–„
                success_improvement = result.success_rate - baseline.success_rate
                print(f"  âœ… æˆåŠŸç‡å‘ä¸Š: {success_improvement:+.1%} ({result.success_rate:.1%} vs {baseline.success_rate:.1%})")
                
                # å¿œç­”æ™‚é–“æ”¹å–„
                response_improvement = (baseline.avg_response_time - result.avg_response_time) / baseline.avg_response_time * 100
                print(f"  âš¡ å¿œç­”æ™‚é–“çŸ­ç¸®: {response_improvement:+.1f}% ({result.avg_response_time:.2f}s vs {baseline.avg_response_time:.2f}s)")
        
        print("\n" + "="*80)
        print("ğŸ’¡ æ¨å¥¨è¨­å®š")
        print("="*80)
        
        # æœ€é«˜æ€§èƒ½ã®æ–¹å¼ã‚’ç‰¹å®š
        best_rps = max(results, key=lambda r: r.requests_per_second)
        best_success = max(results, key=lambda r: r.success_rate)
        best_response = min(results, key=lambda r: r.avg_response_time if r.avg_response_time > 0 else float('inf'))
        
        print(f"ğŸ† æœ€é«˜RPS: {best_rps.method} ({best_rps.requests_per_second:.1f} req/s)")
        print(f"ğŸ¯ æœ€é«˜æˆåŠŸç‡: {best_success.method} ({best_success.success_rate:.1%})")
        print(f"âš¡ æœ€é€Ÿå¿œç­”: {best_response.method} ({best_response.avg_response_time:.2f}s)")
        
        # ç·åˆè©•ä¾¡
        print(f"\nğŸŒŸ ç·åˆæ¨å¥¨: ", end="")
        if best_rps == best_success == best_response:
            print(f"{best_rps.method}")
        else:
            print("è² è·åˆ†æ•£æ–¹å¼ï¼ˆãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½ï¼‰")


async def run_comprehensive_benchmark():
    """åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œ"""
    benchmark = PerformanceBenchmark()
    results = []
    
    # ãƒ†ã‚¹ãƒˆè¨­å®š
    concurrent_users = 20
    timeout = 30.0
    
    try:
        # 1. å˜ä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        result = await benchmark.benchmark_single_instance(concurrent_users, timeout)
        results.append(result)
        
        # 2. ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«
        result = await benchmark.benchmark_connection_pool(concurrent_users, pool_size=10, timeout=timeout)
        results.append(result)
        
        # 3. è² è·åˆ†æ•£å™¨ï¼ˆã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ï¼‰
        result = await benchmark.benchmark_load_balancer(concurrent_users, LoadBalanceStrategy.ADAPTIVE, timeout)
        results.append(result)
        
        # 4. è² è·åˆ†æ•£å™¨ï¼ˆæœ€å°‘æ¥ç¶šæ•°ï¼‰
        result = await benchmark.benchmark_load_balancer(concurrent_users, LoadBalanceStrategy.LEAST_CONNECTIONS, timeout)
        results.append(result)
        
        # çµæœè¡¨ç¤º
        benchmark.print_benchmark_results(results)
        
        return results
        
    except Exception as e:
        logger.error(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return []


async def stress_test(concurrent_users: int = 50, duration_seconds: int = 60):
    """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ”¥ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹ ({concurrent_users}ãƒ¦ãƒ¼ã‚¶ãƒ¼, {duration_seconds}ç§’)")
    
    load_balancer = await get_load_balancer(LoadBalanceStrategy.ADAPTIVE)
    
    start_time = time.time()
    end_time = start_time + duration_seconds
    
    success_count = 0
    error_count = 0
    
    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯å­¦ç¿’æ”¯æ´AIã§ã™ã€‚"},
        {"role": "user", "content": "ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆä¸­ã§ã™ã€‚"}
    ]
    
    async def stress_request():
        nonlocal success_count, error_count
        try:
            async with await load_balancer.get_client() as client:
                response = await asyncio.wait_for(
                    client.generate_response_async(messages),
                    timeout=30.0
                )
                success_count += 1
        except Exception:
            error_count += 1
    
    # ç¶™ç¶šçš„ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
    tasks = []
    while time.time() < end_time:
        # åŒæ™‚å®Ÿè¡Œæ•°ã‚’åˆ¶å¾¡
        if len(tasks) < concurrent_users:
            task = asyncio.create_task(stress_request())
            tasks.append(task)
        
        # å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤
        tasks = [task for task in tasks if not task.done()]
        
        await asyncio.sleep(0.1)  # å°‘ã—å¾…æ©Ÿ
    
    # æ®‹ã‚Šã®ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã¾ã§å¾…æ©Ÿ
    if tasks:
        await asyncio.gather(*tasks, return_exceptions=True)
    
    actual_duration = time.time() - start_time
    total_requests = success_count + error_count
    
    print(f"âœ… ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†:")
    print(f"   æœŸé–“: {actual_duration:.1f}ç§’")
    print(f"   ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {total_requests}")
    print(f"   æˆåŠŸ: {success_count} ({success_count/total_requests:.1%})")
    print(f"   ã‚¨ãƒ©ãƒ¼: {error_count} ({error_count/total_requests:.1%})")
    print(f"   å¹³å‡RPS: {total_requests/actual_duration:.1f}")


if __name__ == "__main__":
    # åŸºæœ¬ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    asyncio.run(run_comprehensive_benchmark())
    
    # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
    asyncio.run(stress_test(concurrent_users=30, duration_seconds=30))